# Node.js FFmpeg Encode Upload

A comprehensive Node.js backend server for video transcoding and processing, built with Express.js, FFmpeg, and AWS S3 integration. This server provides a complete video processing pipeline with background workers, job queuing, and automatic file management.

## Features

- ğŸ¬ **Video Transcoding**: Full FFmpeg integration with AV1 codec support
- â˜ï¸ **S3 Storage**: Upload, download, and manage video files in AWS S3 (or S3-compatible storage)
- âš™ï¸ **Job Management**: SQLite-based asynchronous job processing with status management
- ğŸ¯ **Quality Presets**: Transcoding presets definition structure (720p, 1080p with AV1)
- ğŸš€ **Express.js API**: RESTful API integration
- ğŸ”§ **Development Tools**: Hot reloading with nodemon, AWS s3 service mock with s3rver
- ğŸ§ª **Comprehensive Testing**: End-to-end testing with automated workflow validation

## Project Structure

```
nodejs-ffmpeg-encode-upload/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ e2e-test.js              # End-to-end testing script
â”‚   â”œâ”€â”€ client_upload.js         # Mocking client upload
â”‚   â””â”€â”€ create-sqlite-db.sh      # Database creation script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/             # Business logic controllers
â”‚   â”‚   â”œâ”€â”€ echoController.js    # Debug echo endpoints
â”‚   â”‚   â””â”€â”€ videoController.js   # Video transcoding controller
â”‚   â”œâ”€â”€ routes/                  # API route definitions
â”‚   â”‚   â”œâ”€â”€ echo.js             # Echo routes
â”‚   â”‚   â””â”€â”€ video.js            # Video processing routes
â”‚   â”œâ”€â”€ config/                 # Configuration files
â”‚   â”‚   â””â”€â”€ config.js           # Environment-based configuration
â”‚   â”œâ”€â”€ data/                   # Data access layer
â”‚   â”‚   â”œâ”€â”€ data-access.js      # Abstract data access interface
â”‚   â”‚   â””â”€â”€ sqlite-data-access.js # SQLite implementation
â”‚   â”œâ”€â”€ utils/                  # Utility functions
â”‚   â”‚   â”œâ”€â”€ ffmpeg-utils.js     # FFmpeg configuration and presets
â”‚   â”‚   â”œâ”€â”€ s3-service.js       # S3 service wrapper
â”‚   â”‚   â”œâ”€â”€ sqlite-wrapper.js   # SQLite utilities
â”‚   â”‚   â””â”€â”€ utils.js            # General utilities
â”‚   â”œâ”€â”€ workers/                # Background workers
â”‚   â”‚   â””â”€â”€ video-transcode-worker.js # Video transcoding worker
â”‚   â”œâ”€â”€ test/                   # Component tests
â”‚   â”‚   â”œâ”€â”€ test-ffmpeg-transcoder.js
â”‚   â”‚   â”œâ”€â”€ test-s3-service.js
â”‚   â”‚   â””â”€â”€ test-sqlite-integration.js
â”‚   â””â”€â”€ main.js                 # Main server entry point
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Quick Start

### Prerequisites

1. **Node.js+** and npm installed
2. **FFmpeg** and **FFprobe** installed and available in $PATH
3. **Ports 3000 and 4568** available (for local server and S3 mock)

### Installation

1. Clone the repository and install dependencies:

```bash
git clone <repository-url>
cd nodejs-ffmpeg-encode-upload
npm install
```

2. Install FFmpeg:

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**Windows:**
- Download from [FFmpeg official website](https://ffmpeg.org/download.html)
- Add to PATH environment variable

3. Check `src/config/config.js` for necessary environment variables and adjust as needed.

### Running End-to-End Tests

**It's strongly recommended to run end-to-end tests locally for dependency check and workflow verification.**

Test the complete workflow automatically:

```bash
npm run test-e2e
```

This will automatically:
- Install dependencies
- Start required services (S3 mock, HTTP server)
- Create test videos
- Test upload and transcoding workflows
- Validate results and clean up

A successful E2E test run produces output like this:

```
ğŸš€ Node.js FFmpeg Encode Upload - End-to-End Test Suite
========================================================
ğŸ“… Started at: 2025-08-08T14:08:46.489Z
ğŸ”§ Config: Server=http://127.0.0.1:3000, S3rver=127.0.0.1:4568

ğŸ” Step 1: Checking Prerequisites
=====================================
âœ… Dependencies verified
âœ… Required ports available
âœ… Temp directory ready

ğŸ›¢ Step 2: Preparing Database
=====================================
ğŸ“¦ Creating SQLite database...
âœ… SQLite database created successfully

ğŸ¬ Step 3: Creating Test Video Files
=====================================
ğŸ“¹ Generating test video with FFmpeg...
âœ… Test video created: /Users/ylink/nodejs-ffmpeg-encode-upload/temp/e2e-test-video.mp4
ğŸ“Š Video size: 0.45 MB

ğŸŒ Step 4: Starting Services
=====================================
ğŸ“¦ Starting s3rver...
âœ… s3rver started successfully
ğŸŒ Starting HTTP server...
âœ… HTTP server started successfully
âœ… Services verification passed

ğŸ“¤ Step 5: Testing Upload Workflow
=====================================
ğŸ“¤ Uploading test video to S3...
âœ… Video uploaded successfully: uploads/e2e-test-video.mp4

ğŸ”„ Step 6: Testing Transcoding Workflow
=====================================
ğŸ¯ Testing transcode with preset: 720p30av1
ğŸ”„ Transcode job started: transcode_1754662149323_y5443md28
ğŸ“Š Polling job status...
ğŸ“Š Job transcode_1754662149323_y5443md28 state: completed (attempt 1)
âœ… Transcode 720p30av1 completed successfully
ğŸ¯ Testing transcode with preset: 1080p30av1
ğŸ”„ Transcode job started: transcode_1754662151353_eb8ys53uz
ğŸ“Š Polling job status...
ğŸ“Š Job transcode_1754662151353_eb8ys53uz state: progressing (attempt 1)
ğŸ“Š Job transcode_1754662151353_eb8ys53uz state: completed (attempt 2)
âœ… Transcode 1080p30av1 completed successfully

ğŸ“¥ Step 7: Downloading and Validating Transcoded Videos
========================================================
ğŸ“¥ Downloading transcoded video: uploads/e2e-test-video_720p30av1.mp4
ğŸ“Š Downloaded file size: 0.23 MB
âœ… Downloaded: uploads/e2e-test-video_720p30av1.mp4
ğŸ” Validating video properties for 720p30av1...
âœ… Video validation passed for 720p30av1
   ğŸ¬ Codec: av1
ğŸ“¥ Downloading transcoded video: uploads/e2e-test-video_1080p30av1.mp4
ğŸ“Š Downloaded file size: 0.30 MB
âœ… Downloaded: uploads/e2e-test-video_1080p30av1.mp4
ğŸ” Validating video properties for 1080p30av1...
âœ… Video validation passed for 1080p30av1

ğŸ‰ All workflow tests completed successfully!

ğŸ§¹ Step 8: Cleaning Up Resources
=====================================
ğŸ›‘ Stopping HTTP server...
âœ… HTTP server stopped
ğŸ›‘ Stopping s3rver...
âœ… s3rver stopped
ğŸ—‘ï¸ Cleaning up test files...
âœ… Test files cleaned up

ğŸ“Š End-to-End Test Report
==========================================
ğŸ•’ Duration: 45.2 seconds
ğŸ“ˆ Success Rate: 100.0%
âœ… Passed: 12
âŒ Failed: 0
ğŸ“Š Total: 12

ğŸ‰ All tests passed! End-to-end testing completed successfully.
```

### Basic Usage

1. **Start the server:**

```bash
npm start
```

The server will start on `http://localhost:3000`.

2. **Upload a video file to S3:**

```bash
# Using the built-in upload client
node scripts/client_upload.js /path/to/your/video.mp4
```

3. **Start a transcoding job:**

```bash
curl -X POST http://localhost:3000/api/video/transcode \
  -H "Content-Type: application/json" \
  -d '{
    "s3Key": "uploads/your-video.mp4",
    "resolutionPreset": "720p30av1"
  }'
```

4. **Check job status:**

```bash
curl http://localhost:3000/api/video/jobs/<job-id>
```

## API Endpoints

### Server Information
- `GET /` - Server information and available endpoints

### Echo Endpoints (Debug)
- `GET /api/echo` - Echo GET request details with headers, query params, etc.
- `POST /api/echo` - Echo POST request with body data

### Video Processing
- `POST /api/video/transcode` - Start a video transcoding job
- `GET /api/video/jobs/:jobId` - Get transcoding job status
- `POST /api/video/jobs/:jobId/callback` - Job completion callback (internal use)

## Video Transcoding API

### Start Transcoding Job

**Endpoint:** `POST /api/video/transcode`

**Request Body:**
```json
{
  "s3Key": "uploads/input-video.mp4",
  "resolutionPreset": "720p30av1"
}
```

**Available Resolution Presets:**
- `720p30av1` - 1280x720, 30fps, AV1 codec
- `1080p30av1` - 1920x1080, 30fps, AV1 codec  
- `1080p60av1` - 1920x1080, 60fps, AV1 codec

**Response:**
```json
{
  "message": "Transcode job started",
  "method": "POST",
  "timestamp": "2025-08-08T14:08:46.489Z",
  "jobId": "transcode_1754662149323_y5443md28",
  "input": {
    "s3Key": "uploads/input-video.mp4",
    "fileName": "input-video.mp4"
  },
  "targetPreset": "720p30av1",
  "status": "progressing"
}
```

### Check Job Status

**Endpoint:** `GET /api/video/jobs/:jobId`

**Response (In Progress):**
```json
{
  "jobId": "transcode_1754662149323_y5443md28",
  "state": "progressing"
}
```

**Response (Completed):**
```json
{
  "jobId": "transcode_1754662149323_y5443md28",
  "state": "completed",
  "callback": {
    "success": true,
    "detail": {
      "inputS3Key": "uploads/input-video.mp4",
      "outputS3Key": "uploads/input-video_720p30av1.mp4",
      "quality": "720p30av1",
      "jobId": "transcode_1754662149323_y5443md28",
      "jobDuration": "15432.50 ms"
    }
  }
}
```

**Job States:**
- `waiting` - Job queued but not started
- `progressing` - Job currently being processed
- `completed` - Job finished successfully
- `failed` - Job failed with error

## Video Transcoding Examples

### Basic Video Upload and Transcoding

1. **Upload a video file:**
```bash
node scripts/client_upload.js /path/to/video.mp4
# Output: S3 Key: uploads/video.mp4
```

2. **Start transcoding to 720p AV1:**
```bash
curl -X POST http://localhost:3000/api/video/transcode \
  -H "Content-Type: application/json" \
  -d '{
    "s3Key": "uploads/video.mp4",
    "resolutionPreset": "720p30av1"
  }'
# Output: {"jobId": "transcode_1754662149323_y5443md28", ...}
```

3. **Monitor job progress:**
```bash
curl http://localhost:3000/api/video/jobs/transcode_1754662149323_y5443md28
```

## Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client Apps   â”‚    â”‚   S3 Storage    â”‚    â”‚     Database    â”‚
â”‚                 â”‚    â”‚  (AWS S3 or     â”‚    â”‚   (SQLite)      â”‚
â”‚ - Web Apps      â”‚    â”‚   s3rver mock)  â”‚    â”‚                 â”‚
â”‚ - Upload Tool   â”‚    â”‚                 â”‚    â”‚ - Job Tracking  â”‚
â”‚ - API Clients   â”‚    â”‚ - Video Files   â”‚    â”‚ - Status        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚ HTTP API              â”‚ S3 API                â”‚ SQL
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Express Server â”‚
              â”‚                 â”‚
              â”‚ - REST API      â”‚
              â”‚ - Job Mgmt      â”‚
              â”‚ - File Upload   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Spawn Process
                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Worker Process  â”‚
              â”‚                 â”‚
              â”‚ - Download S3   â”‚
              â”‚ - FFmpeg        â”‚
              â”‚ - Upload Result â”‚
              â”‚ - Update Status â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Upload**: Client uploads video â†’ S3 Storage
2. **Job Creation**: API creates transcoding job â†’ Database  
3. **Worker Spawn**: Server spawns background worker process
4. **Processing**: Worker downloads â†’ transcodes â†’ uploads result
5. **Status Update**: Worker reports completion â†’ Database
6. **Client Polling**: Client checks job status via API

### Job States

```
[waiting] â†’ [progressing] â†’ [completed]
                  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â†’ [failed]
```

**Note:** Currently the retry mechanism to return jobs from `failed` state back to `waiting` state is not implemented.

## Development

### Development Mode

Start with hot reloading:

```bash
npm run dev
```

### Adding New Features

1. **Controllers**: Business logic in `src/controllers/`
2. **Routes**: API endpoints in `src/routes/`
3. **Utils**: Helper functions in `src/utils/`
4. **Workers**: Background processing in `src/workers/`
5. **Tests**: Component tests in `src/test/`

### Adding New Transcoding Presets

Edit `src/utils/ffmpeg-utils.js` and add to `QUALITY_TO_PRESETS`:

```javascript
export const QUALITY_TO_PRESETS = {
  "480p30av1": {
    width: 854,
    height: 480,
    crf: 52,
    preset: "12",
    filters: { fps: 30 },
    // ... advanced options
  },
  // ... existing presets
};
```

## License

ISC
